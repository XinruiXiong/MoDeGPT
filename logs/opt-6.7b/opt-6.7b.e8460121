2025-04-30 15:23:56,277 - INFO - Loading model: facebook/opt-6.7b
2025-04-30 15:23:56,277 - INFO - Loading model from: facebook/opt-6.7b
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2025-04-30 15:24:05,303 - INFO - ✔ Loaded with device_map='auto', float16, low_cpu_mem_usage=True.
2025-04-30 15:24:05,305 - INFO - Loading calibration and evaluation texts...
2025-04-30 15:24:15,284 - INFO - Evaluating original model (for baseline perplexity)...
2025-04-30 15:24:19,587 - INFO - Original model perplexity on WikiText2: 8.47
2025-04-30 15:24:19,589 - INFO - Calibrating model...
You shouldn't move a model that is dispatched using accelerate hooks.
2025-04-30 15:24:19,656 - INFO - Detected architecture: opt
Traceback (most recent call last):
  File "/u/home/x/xxiong/MoDeGPT/run_modegpt.py", line 354, in <module>
    main()
  File "/u/home/x/xxiong/MoDeGPT/run_modegpt.py", line 257, in main
    cov_mlp, cov_q, cov_k, bi_scores = calibrate_model(model, tokenizer, calib_texts, device=device, logger=logger)
  File "/u/home/x/xxiong/MoDeGPT/calibration.py", line 244, in calibrate_model
    outputs = model(**inputs, output_hidden_states=True)
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/accelerate/hooks.py", line 176, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py", line 1117, in forward
    outputs = self.model.decoder(
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py", line 883, in forward
    layer_outputs = decoder_layer(
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/accelerate/hooks.py", line 176, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py", line 521, in forward
    hidden_states = self.self_attn_layer_norm(hidden_states)
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1739, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1750, in _call_impl
    return forward_call(*args, **kwargs)
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/accelerate/hooks.py", line 176, in new_forward
    output = module._old_forward(*args, **kwargs)
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/torch/nn/modules/normalization.py", line 217, in forward
    return F.layer_norm(
  File "/u/home/x/xxiong/miniforge3/envs/modegpt/lib/python3.10/site-packages/torch/nn/functional.py", line 2910, in layer_norm
    return torch.layer_norm(
RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:1 and cuda:0! (when checking argument for argument weight in method wrapper_CUDA__native_layer_norm)
